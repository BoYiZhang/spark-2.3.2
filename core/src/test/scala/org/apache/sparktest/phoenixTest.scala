package org.apache.sparktest

//import org.apache.spark.SparkContext
//import org.apache.spark.sql.SQLContext
//import org.apache.phoenix.spark._

class phoenixTest {

  def main(args: Array[String]): Unit ={
//    val array = new Array[String](1,2,3,4,5).iterator.buffered




//    val sc = new SparkContext("local", "phoenix-test")
//    val sqlContext = new SQLContext(sc)
//
//    val df = sqlContext.load(
//      "org.apache.phoenix.spark",
//      Map("table" -> "TABLE1", "zkUrl" -> "phoenix-server:2181")
//    )
//
//    df
//      .filter(df("COL1") === "test_row_1" && df("ID") === 1L)
//      .select(df("ID"))
//      .show
//

  }

}
